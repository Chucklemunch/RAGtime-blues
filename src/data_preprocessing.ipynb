{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73ca3771-e64b-4a17-a6fc-493efb8784ea",
   "metadata": {},
   "source": [
    "# Gets from Pub Med and process it so it can be chunked, vectorized, and stored in Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef88f93-0052-4fbf-ae6f-31eacda94f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from lxml import etree\n",
    "from io import BytesIO\n",
    "import re\n",
    "import spacy\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923491be-3caa-45d9-97c7-13098d796b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = \"charlie.kotula@gmail.com\"\n",
    "\n",
    "# Search query for getting relevant research articles\n",
    "query = \"\"\"\n",
    "(\n",
    "  rehabilitation AND \"physical therapy\" OR \"return to sport\" OR \"return to play\"\n",
    ") AND (\n",
    "  injury OR surgery OR postoperative OR musculoskeletal\n",
    ") AND (\n",
    "  exercise OR \"therapeutic exercise\" OR training\n",
    ") AND (\n",
    "  review[pt] OR systematic review[pt] OR meta-analysis[pt]\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "def get_ids_with_metadata(query):\n",
    "    \"\"\"\n",
    "    Gets PMC article UIDs, PMCIDs, and titles based on search query\n",
    "\n",
    "    Args: query (str) - search query used to retrieve PMC articles\n",
    "    Returns: metadata (dict) - dictionary containing PMCID and titles corresponding\n",
    "        to the articles UID\n",
    "    \"\"\"\n",
    "    # Get relevant UIDs and titles\n",
    "    metadata = []\n",
    "    handle = Entrez.esearch(\n",
    "        db='pmc',\n",
    "        term=query,\n",
    "        retmax=10, # CHANGE\n",
    "    )\n",
    "    \n",
    "    # Get relevant articles\n",
    "    uids = Entrez.read(handle)['IdList']\n",
    "    handle.close()\n",
    "    \n",
    "    # Get summaries for metadata\n",
    "    summary = Entrez.esummary(\n",
    "        db='pmc',\n",
    "        id=','.join(uids)\n",
    "    )\n",
    "    records = Entrez.read(summary)\n",
    "    \n",
    "    # Map UIDs to titles and pmids\n",
    "    for rec in records:\n",
    "        title = rec['Title'].lower()\n",
    "        title = re.sub(r'[^a-z0-9]+', '_', title)\n",
    "    \n",
    "        metadata.append(\n",
    "            {\n",
    "                'uid': rec['Id'],\n",
    "                'pmcid': rec['ArticleIds']['pmcid'],\n",
    "                'title': title\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# Create metadata list to be used in multiprocessing\n",
    "metadata = get_ids_with_metadata(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e854873-fc28-4ef7-a355-c19f702269b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 534 documents in 2.889578104019165 seconds\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import process_article\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #### Multiprocessing of articles ####\n",
    "    documents = []\n",
    "    \n",
    "    ### Processes articles one at a time\n",
    "    # for article in tqdm(metadata):\n",
    "    #     # process article (extract text, clean, chunk)d\n",
    "    #     docs = process_article(article)\n",
    "    #     documents.append(docs)\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    ### Processes multiple articles in parallel\n",
    "    with ProcessPoolExecutor(max_workers=8) as executor:\n",
    "        futures = [executor.submit(process_article, article) for article in metadata]\n",
    "    \n",
    "        for future in as_completed(futures):\n",
    "            documents.extend(future.result())\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f'processed {len(documents)} documents in {end_time - start_time} seconds')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e4c78-9bcc-4688-8921-7f767366cd39",
   "metadata": {},
   "source": [
    "# Embedding using OpenAI and Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132074ec-9e06-49ce-9b4a-5b0b707ad8b1",
   "metadata": {},
   "source": [
    "### To run the Qdrant docker:\n",
    "\n",
    "`docker run -p 6333:6333 -p 6334:6334 \\\n",
    "    -v \"$(pwd)/qdrant_storage:/qdrant/storage:z\" \\\n",
    "    qdrant/qdrant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf3f7eb2-ae3e-4f8a-8704-d843b0590971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "import uuid\n",
    "from data_preprocessing import embed_and_upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a47f3a7b-60a9-4c2f-b28c-72ce0cf06474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched(iterable, batch_size):\n",
    "    for i in range(0, len(iterable), batch_size):\n",
    "        yield iterable[i : i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179c1ba1-40d0-4343-a43d-90db9dcf6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_docs = [batch for batch in batched(documents, 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2e04ba3-3dca-4632-97de-adf7ba7839c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"rehab_collection\",\n",
    "    vectors_config=VectorParams(\n",
    "        size=3072,\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6444c76f-2faf-4fd9-93d6-dc001eb784ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69da3101-81cb-4ee6-99c5-7b4243905b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 534 embedded and upserted in 1.7183849811553955 seconds\n"
     ]
    }
   ],
   "source": [
    "### Multiprocessing for embedding and storage of chunks\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                embed_and_upsert, \n",
    "                document_batch=batch,\n",
    "                client=client,\n",
    "                embed_model=embeddings\n",
    "            )\n",
    "            for batch in batched_docs\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            future.result()\n",
    "        except Exception as e:\n",
    "            print(\"batch failed: \", e)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f'processed {len(documents)} embedded and upserted in {end_time - start_time} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0268a86e-bb9a-4b9a-a182-b55cc59cd1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountResult(count=534)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking db\n",
    "client.count(collection_name='rehab_collection', exact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "847db8c5-af73-4802-b95f-79cd2a44a0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wipe db\n",
    "client.delete_collection('rehab_collection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ecb528-a028-485a-9905-e7b4e253c758",
   "metadata": {},
   "source": [
    "# Testing Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd7410-9214-4076-8896-337784de1ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
